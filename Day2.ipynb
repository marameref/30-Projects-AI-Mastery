{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b976TpCnP4Zd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Classifier Using Keras and TensorFlow\n",
        "- This code demonstrates how to build a simple image classifier using Keras and TensorFlow.It includes data preprocessing, model building, training, and evaluation.\n",
        "\"\"\"\n",
        "Steps:\n",
        "1. Import necessary libraries\n",
        "2. Load MNIST dataset\n",
        "3. Preprocess the data\n",
        "4. Build the model\n",
        "5. Train the model\n",
        "6. Evaluate the model\n",
        "7. Make predictions"
      ],
      "metadata": {
        "id": "KRIR7cg6ScZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "kpGzoeU6xe_U"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the MNIST dataset\n",
        "# The MNIST dataset consists of 70,000 grayscale images of handwritten digits (0-9)\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpevMaT9xl7x",
        "outputId": "39c699f0-8f20-48bf-c540-be76055f103f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Preprocessing - Normalize pixel values (0 to 255) to the range 0 to 1\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "sQ6NnV8dxubY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Reshape the images to include channel dimension (grayscale = 1 channel)\n",
        "# Shape becomes (num_samples, 28, 28, 1)\n",
        "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
        "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))"
      ],
      "metadata": {
        "id": "yfUhx2eix-qE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: One-hot encode the labels (e.g., label 3 becomes [0 0 0 1 0 0 0 0 0 0])\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "-bpUsp_IzyUl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Build the Convolutional Neural Network (CNN) model\n",
        "model = models.Sequential()"
      ],
      "metadata": {
        "id": "BpVaA3oWz3Yg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Flatten the output of the last conv layer into 1D vector\n",
        "model.add(layers.Flatten())"
      ],
      "metadata": {
        "id": "-LjN6Mu4z6_3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Fully connected (dense) layer with 64 neurons\n",
        "model.add(layers.Dense(64, activation='relu'))"
      ],
      "metadata": {
        "id": "L7J_D2Kfz_mq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Output layer with 10 neurons (one per digit), using softmax activation\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "NOtJPblu0DjG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8W8BElS00GPk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Train the model for 10 epochs with a batch size of 64\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=64,\n",
        "          validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CaCHqUB0KON",
        "outputId": "35b95cbb-e8e7-4d0c-e9e4-94e3c6dbe88b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.3004 - val_accuracy: 0.9164 - val_loss: 0.2866\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.2936 - val_accuracy: 0.9198 - val_loss: 0.2814\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9195 - loss: 0.2796 - val_accuracy: 0.9200 - val_loss: 0.2772\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9194 - loss: 0.2798 - val_accuracy: 0.9215 - val_loss: 0.2712\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9193 - loss: 0.2736 - val_accuracy: 0.9221 - val_loss: 0.2676\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9202 - loss: 0.2758 - val_accuracy: 0.9236 - val_loss: 0.2636\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9224 - loss: 0.2696 - val_accuracy: 0.9252 - val_loss: 0.2612\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9245 - loss: 0.2619 - val_accuracy: 0.9259 - val_loss: 0.2565\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9251 - loss: 0.2578 - val_accuracy: 0.9277 - val_loss: 0.2521\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9257 - loss: 0.2546 - val_accuracy: 0.9268 - val_loss: 0.2499\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bebda8fcf10>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzBIE4Jl0PEo",
        "outputId": "ea4242f9-6ca6-45ba-c3e3-1480580f5ddd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2838\n",
            "Test accuracy: 92.68%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: Predict the label of the first test image\n",
        "predictions = model.predict(test_images)\n",
        "print(f\"Prediction for first test image: {np.argmax(predictions[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6o2l4pH0W7_",
        "outputId": "1ea51f6f-bb1b-4737-a3bb-73d8798a784c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Prediction for first test image: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unit Tests (using pytest)"
      ],
      "metadata": {
        "id": "RvAMOat104bU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_shape_of_input():\n",
        "    assert train_images.shape == (60000, 28, 28, 1)\n",
        "    assert test_images.shape == (10000, 28, 28, 1)"
      ],
      "metadata": {
        "id": "_UG7CE2S02So"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_label_encoding():\n",
        "    assert train_labels.shape == (60000, 10)\n",
        "    assert test_labels.shape == (10000, 10)"
      ],
      "metadata": {
        "id": "aqG2Gdz_1AF9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_output_shape():\n",
        "    assert model.output_shape == (None, 10)"
      ],
      "metadata": {
        "id": "MP3aSvrJ1DqB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_prediction_shape():\n",
        "    assert predictions.shape == (10000, 10)"
      ],
      "metadata": {
        "id": "3DjTf-ev1G_X"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_prediction_sum():\n",
        "    # The sum of probabilities for each prediction should be close to 1\n",
        "    assert np.allclose(np.sum(predictions[0]), 1.0, atol=1e-5)"
      ],
      "metadata": {
        "id": "-76MuMRB1Lds"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_accuracy_range():\n",
        "    assert 0 <= test_acc <= 1"
      ],
      "metadata": {
        "id": "xcalvSV71OoN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loss_positive():\n",
        "    assert test_loss >= 0"
      ],
      "metadata": {
        "id": "vxu07R8p1RgW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_first_prediction_valid():\n",
        "    first_pred = np.argmax(predictions[0])\n",
        "    assert 0 <= first_pred <= 9"
      ],
      "metadata": {
        "id": "C-aIsfg51VmS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_trainable():\n",
        "    assert model.trainable is True"
      ],
      "metadata": {
        "id": "aIhYy4DM1YbG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_has_layers():\n",
        "    assert len(model.layers) > 0"
      ],
      "metadata": {
        "id": "uh3fFDwO1bRx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "06SVgggc1eT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# 📄 Technical Documentation: CNN for MNIST Digit Classification\n",
        "\n",
        "## 🧠 Project Overview\n",
        "\n",
        "This project builds and evaluates a **Convolutional Neural Network (CNN)** using **TensorFlow and Keras** to classify handwritten digits from the **MNIST dataset**. The goal is to accurately recognize digits (0–9) from grayscale images of size 28x28 pixels.\n",
        "\n",
        "---\n",
        "\n",
        "## 📦 Dependencies\n",
        "\n",
        "Make sure the following Python libraries are installed:\n",
        "\n",
        "```bash\n",
        "pip install numpy tensorflow\n",
        "```\n",
        "\n",
        "### Imports used:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 📊 Dataset\n",
        "\n",
        "### MNIST Dataset\n",
        "\n",
        "- **Shape:** 60,000 training samples, 10,000 test samples\n",
        "- **Format:** Grayscale images, 28x28 pixels\n",
        "- **Labels:** Integers (0 to 9) representing digits\n",
        "\n",
        "Keras provides the dataset via:\n",
        "\n",
        "```python\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🔧 Preprocessing\n",
        "\n",
        "### 1. **Normalization**\n",
        "\n",
        "Pixel values are divided by 255.0 to scale them from `[0, 255]` → `[0.0, 1.0]`.\n",
        "\n",
        "```python\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "```\n",
        "\n",
        "### 2. **Reshaping**\n",
        "\n",
        "The CNN expects input of shape `(height, width, channels)`. Since MNIST images are grayscale, we add one channel.\n",
        "\n",
        "```python\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "```\n",
        "\n",
        "### 3. **One-Hot Encoding**\n",
        "\n",
        "The class labels are converted to categorical format for classification tasks.\n",
        "\n",
        "```python\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🧱 CNN Architecture\n",
        "\n",
        "### Model Structure:\n",
        "\n",
        "```python\n",
        "model = models.Sequential()\n",
        "\n",
        "# Conv Layer 1\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Conv Layer 2\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Conv Layer 3\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Fully Connected Layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "```\n",
        "\n",
        "### Summary:\n",
        "\n",
        "| Layer Type       | Output Shape | Parameters |\n",
        "|------------------|--------------|------------|\n",
        "| Conv2D (32, 3x3) | (26, 26, 32) | 320        |\n",
        "| MaxPooling2D     | (13, 13, 32) | 0          |\n",
        "| Conv2D (64, 3x3) | (11, 11, 64) | 18,496     |\n",
        "| MaxPooling2D     | (5, 5, 64)   | 0          |\n",
        "| Conv2D (64, 3x3) | (3, 3, 64)   | 36,928     |\n",
        "| Flatten          | 576          | 0          |\n",
        "| Dense (64)       | 64           | 36,928     |\n",
        "| Dense (10)       | 10           | 650        |\n",
        "\n",
        "---\n",
        "\n",
        "## ⚙️ Model Compilation\n",
        "\n",
        "```python\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "```\n",
        "\n",
        "- **Optimizer:** `adam` – efficient and adaptive\n",
        "- **Loss Function:** `categorical_crossentropy` – suitable for multi-class classification\n",
        "- **Metric:** `accuracy` – tracks prediction correctness\n",
        "\n",
        "---\n",
        "\n",
        "## 🏋️ Model Training\n",
        "\n",
        "```python\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_data=(test_images, test_labels))\n",
        "```\n",
        "\n",
        "- **Epochs:** 5 full passes over the dataset\n",
        "- **Batch Size:** 64 samples per batch\n",
        "- **Validation:** monitored on test data\n",
        "\n",
        "---\n",
        "\n",
        "## 📈 Evaluation\n",
        "\n",
        "```python\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc * 100:.2f}%\")\n",
        "```\n",
        "\n",
        "This outputs the test accuracy, giving insight into the model's generalization ability.\n",
        "\n",
        "---\n",
        "\n",
        "## 🔍 Predictions\n",
        "\n",
        "```python\n",
        "predictions = model.predict(test_images)\n",
        "print(f\"Prediction for first test image: {np.argmax(predictions[0])}\")\n",
        "```\n",
        "\n",
        "`predictions` contains probability vectors; `np.argmax` finds the most likely class.\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Unit Tests (10)\n",
        "\n",
        "These tests check assumptions and outputs in the training pipeline.\n",
        "\n",
        "```python\n",
        "import unittest\n",
        "\n",
        "class TestMNISTModel(unittest.TestCase):\n",
        "\n",
        "    def test_shape_of_images(self):\n",
        "        self.assertEqual(train_images.shape, (60000, 28, 28, 1))\n",
        "        self.assertEqual(test_images.shape, (10000, 28, 28, 1))\n",
        "\n",
        "    def test_dtype_and_range(self):\n",
        "        self.assertTrue(np.all(train_images >= 0.0) and np.all(train_images <= 1.0))\n",
        "\n",
        "    def test_label_encoding(self):\n",
        "        self.assertEqual(train_labels.shape[1], 10)\n",
        "        self.assertEqual(test_labels.shape[1], 10)\n",
        "\n",
        "    def test_model_output_shape(self):\n",
        "        self.assertEqual(model.output_shape, (None, 10))\n",
        "\n",
        "    def test_model_input_shape(self):\n",
        "        self.assertEqual(model.input_shape, (None, 28, 28, 1))\n",
        "\n",
        "    def test_prediction_shape(self):\n",
        "        pred = model.predict(test_images[:5])\n",
        "        self.assertEqual(pred.shape, (5, 10))\n",
        "\n",
        "    def test_prediction_sum(self):\n",
        "        pred = model.predict(test_images[:1])\n",
        "        self.assertAlmostEqual(np.sum(pred), 1.0, places=5)\n",
        "\n",
        "    def test_prediction_class_type(self):\n",
        "        pred_class = np.argmax(predictions[0])\n",
        "        self.assertIsInstance(pred_class, (int, np.integer))\n",
        "\n",
        "    def test_no_nan_in_predictions(self):\n",
        "        self.assertFalse(np.any(np.isnan(predictions)))\n",
        "\n",
        "    def test_accuracy_above_threshold(self):\n",
        "        self.assertGreater(test_acc, 0.95)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unittest.main(argv=[''], exit=False)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 👨‍💻 Contributors\n",
        "\n",
        "- **Developer:** Engr. Amarachi Omereife\n",
        "- **Tools Used:** Python, NumPy, TensorFlow, Keras\n",
        "\n",
        "---\n",
        "\n",
        "## 🙌 Credits\n",
        "\n",
        "Special thanks to:\n",
        "\n",
        "- **Vvian Araha** for inspiration\n",
        "- All **contributors to the global AI community** for advancing education through free and affordable resources.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 Summary\n",
        "\n",
        "This project shows how to:\n",
        "- Build a deep learning pipeline using TensorFlow\n",
        "- Preprocess image and label data for CNNs\n",
        "- Train and evaluate a digit classification model\n",
        "- Perform predictions and validate with unit tests\n",
        "\n",
        "---\n",
        "⭐ Don’t Forget to Star this Repo!\n",
        "If you found this bootcamp useful, please give it a ⭐ and share it with your fellow AI learners. Your support keeps the open-source flame alive! 🔥\n",
        "\n",
        "---S"
      ],
      "metadata": {
        "id": "YHFPvzg81oVC"
      }
    }
  ]
}